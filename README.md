# Titanic_Machine Learning
### Titanic Machine Learning resolution, learn from the disaster.  Kaggle contest, predict survival on the Titanic. 

**Technology:** Jupyter notebook, Python

**Source:** [Kaggle](https://www.kaggle.com/competitions/titanic)

**Files:** 
- **training set (train.csv):** should be used to build your machine learning models.
- **test set (test.csv):** should be used to see how well your model performs on unseen data
- **Gender_submission.csv:** An example of what a submission file should look like.These predictions assume only female passengers survive.
- **titanic.ipynb:** coding, cleaning, and analysis
- **Titanic_pred_log.csv:** csv document with predictive logistic Regression model for submission in Kaggle 
- **Titanic_pred_tree.csv:** csv document with predictive Regression Tree model for submission in Kaggle 


**Skills:** clean data, data Visualization, ML models logistic Regression and Decision Tree

**Description:** The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck. more info [click here](https://www.kaggle.com/competitions/titanic/overview)

**Results:** Many third-class passengers boarding alone lack age data, which can be either removed or imputed with the mean age. In the analysis, the decision tree outperformed logistic regression with 0.89 accuracy vs. 0.79. However, when tested on Kaggle, results were reversed: 0.73 vs. 0.75 accuracy. Variable review is needed.
